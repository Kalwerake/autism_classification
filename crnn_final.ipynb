{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**CNN-LSTM**\n",
    "\n",
    "cross validation and training of CRNN network. Change directory paths to relevant ones"
   ],
   "metadata": {
    "id": "NWo0lOzg0yDQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#if carrying out on google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "x7HZ8_U5gw8J",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d169fe4d-0a78-4a99-e9a9-fed58eaa43cd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uwsfHpglABlr"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pickle\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# directory storing the DFC dataset\n",
    "data_dir = 'dfc_cc200'"
   ],
   "metadata": {
    "id": "2yVs_neygs8l"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_p = 'phenotype_files/pheno_nn.csv'"
   ],
   "metadata": {
    "id": "XPcjdBW-hK_O"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_raw = pd.read_csv(df_p)"
   ],
   "metadata": {
    "id": "vjX7B4nqhaoU"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_raw.head()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_Akr8gnLsJuY",
    "outputId": "4547627d-70b8-44fe-c87f-c57a0e908e6c"
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  SITE_ID  X  SUB_ID       FILE_ID  AGE_AT_SCAN  SEX  DSM_IV_TR  DX_GROUP\n0    PITT  1   50002  Pitt_0050002        16.77    1          1         1\n1    PITT  2   50003  Pitt_0050003        24.45    1          1         1\n2    PITT  3   50004  Pitt_0050004        19.09    1          1         1\n3    PITT  4   50005  Pitt_0050005        13.73    2          1         1\n4    PITT  5   50006  Pitt_0050006        13.37    1          1         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SITE_ID</th>\n      <th>X</th>\n      <th>SUB_ID</th>\n      <th>FILE_ID</th>\n      <th>AGE_AT_SCAN</th>\n      <th>SEX</th>\n      <th>DSM_IV_TR</th>\n      <th>DX_GROUP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PITT</td>\n      <td>1</td>\n      <td>50002</td>\n      <td>Pitt_0050002</td>\n      <td>16.77</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PITT</td>\n      <td>2</td>\n      <td>50003</td>\n      <td>Pitt_0050003</td>\n      <td>24.45</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PITT</td>\n      <td>3</td>\n      <td>50004</td>\n      <td>Pitt_0050004</td>\n      <td>19.09</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PITT</td>\n      <td>4</td>\n      <td>50005</td>\n      <td>Pitt_0050005</td>\n      <td>13.73</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PITT</td>\n      <td>5</td>\n      <td>50006</td>\n      <td>Pitt_0050006</td>\n      <td>13.37</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# binarize target column and combine with File_id to form dataset annotation file\n",
    "df = pd.DataFrame({'FILE_ID': df_raw.FILE_ID.values,'TARGET':[1 if i == 1 else 0 for i in df_raw.DSM_IV_TR.values]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DfcDataset(Dataset):\n",
    "\n",
    "    def __init__(self,df,dfc_dir):\n",
    "        \"\"\"\n",
    "        :param df: pandas dataframe containing subject ids in column `FILE_ID` and target labels in column `TARGET`\n",
    "        :param dfc_dir: path to subdirectory containing the pickle files\n",
    "        \"\"\"\n",
    "        self.df_main = df\n",
    "        self.dfc_dir = dfc_dir\n",
    "        # get paths to each DFC matrix\n",
    "        self.paths = [os.path.join(dfc_dir,f + '_dfc.npy') for f in df.FILE_ID]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        :param idx: index\n",
    "        :return: 4D tensor with 2 spatial dimensions and 1 temporal [N,1,90,200,200], and label\n",
    "        \"\"\"\n",
    "\n",
    "        dfc_array = np.load(self.paths[idx])# load array\n",
    "        dfc_tensor = [torch.from_numpy(npDfc).type(torch.float) for npDfc in dfc_array] #take each list in dfc_array and turn to torch tensor of type torch.float, otherwise result is float(64)\n",
    "\n",
    "        dfc_stack = torch.stack(dfc_tensor) # make tensor stack of each dfc array\n",
    "\n",
    "        label = self.df_main.loc[idx, 'TARGET'] # class label of idx as np array\n",
    "        label_tensor = torch.tensor(label)\n",
    "        label_tensor = label_tensor.to(torch.float32)\n",
    "\n",
    "        return torch.unsqueeze(dfc_stack, dim= 0),torch.unsqueeze(label_tensor, dim = -1) # turn torch stack to 4D tensor for input into conv3d (channel,depth,height,width), return label as tensor of shape [batch size, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return: length of dataset\n",
    "        \"\"\"\n",
    "        return len(self.df_main)"
   ],
   "metadata": {
    "id": "ve8-kULfe3sk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class crnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(crnn, self).__init__()\n",
    "\n",
    "        #Convolutional layers\n",
    "        self.seq_cnn = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=1,out_channels=8, kernel_size=(2,200,1),stride=(1,1,1), padding_mode = 'reflect'),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(in_channels=8,out_channels=16, kernel_size=(2,1,200),stride=(1,1,1), padding_mode = 'reflect'),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(in_channels=16,out_channels=32, kernel_size=(8,1,1),stride=(2,1,1), padding_mode = 'reflect'),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm3d(32)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        #lstm layer\n",
    "        self.lstm1 = nn.GRU(input_size=32, hidden_size=64, num_layers=1, batch_first = True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.seq_dense = nn.Sequential(\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(16,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.seq_cnn(x)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x,start_dim=2,end_dim=4) # reduce dimensionality for LSTM layer, to 3D tensor\n",
    "        x = x.permute(0,2,1) # transpose to make tensor of size [batch_size, sequence length, feature number]\n",
    "\n",
    "        x,_ = self.lstm1(x)\n",
    "\n",
    "        x = x[:,-1,:] # take output of last LSTM cell\n",
    "\n",
    "        x = self.seq_dense(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "id": "NLY0MUIFe4xl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# set device to GPU if gpu is absent training will be done on CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrKJ8jLc9WAk",
    "outputId": "1d6a8ac3-7f41-4a68-a40b-52fcd9758d38"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model,loss_fn, optimiser ,train_loader, device):\n",
    "  running_loss = 0\n",
    "  epoch_accuracy = []\n",
    "  for j, (x_train,y) in enumerate(train_loader):\n",
    "    optimiser.zero_grad() # zero the gradient at each epoch start\n",
    "    y = y.to(device) # send y to cuda\n",
    "    x_train = x_train.to(device)\n",
    "    prediction = model.forward(x_train)\n",
    "    loss = loss_fn(prediction,y) # loss\n",
    "\n",
    "    accuracy = (torch.round(prediction) == y).float().mean() # calculate accuracy for each mini-batch  take prediction tensor, reshape to 1d detach from computational graph turn to numpy array, round and see if rounded number is equal to label, find mean of this boolean array, this is the accuracy\n",
    "\n",
    "    running_loss += loss.item() # get epoch loss\n",
    "    epoch_accuracy.append(accuracy.item())\n",
    "                \n",
    "\n",
    "    loss.backward() # backward propgation\n",
    "    optimiser.step()\n",
    "    \n",
    "    running_loss += loss.item() # get epoch loss\n",
    "    epoch_accuracy.append(accuracy.item())\n",
    "\n",
    "  return (running_loss, np.mean(epoch_accuracy))\n",
    "\n"
   ],
   "metadata": {
    "id": "82rINVL5QkPp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def validate_one_epoch(model,loss_fn, test_loader, device):\n",
    "  test_loss_run = 0\n",
    "  test_acc_epoch = []\n",
    "  for j, (x_test,y_test) in enumerate(test_loader):\n",
    "    y_test = y_test.to(device)\n",
    "    x_test= x_test.to(device)\n",
    "    test_pred = model.forward(x_test)\n",
    "    test_loss = loss_fn(test_pred,y_test) # loss\n",
    "\n",
    "    test_acc = (torch.round(test_pred) == y_test).float().mean() # calculate accuracy for each mini-batch  take prediction tensor, reshape to 1d detach from computational graph turn to numpy array, round and see if rounded number is equal to label, find mean of this boolean array, this is the accuracy\n",
    "\n",
    "    test_loss_run += test_loss.item()\n",
    "    test_acc_epoch.append(test_acc.item())\n",
    "  \n",
    "  return (test_loss_run, np.mean(test_acc_epoch))"
   ],
   "metadata": {
    "id": "DwHHAxVjTWdW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ],
   "metadata": {
    "id": "fTnSLH2iV9_a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 train_loss: 80.26, accuracy: 0.52,test_loss:4.83, test_acc: 0.53 \n",
      "Epoch 2 train_loss: 79.06, accuracy: 0.52,test_loss:4.75, test_acc: 0.52 \n",
      "Epoch 3 train_loss: 76.86, accuracy: 0.55,test_loss:4.55, test_acc: 0.61 \n",
      "Epoch 4 train_loss: 73.5, accuracy: 0.63,test_loss:4.43, test_acc: 0.67 \n",
      "Epoch 5 train_loss: 66.55, accuracy: 0.73,test_loss:4.43, test_acc: 0.68 \n",
      "Epoch 6 train_loss: 58.3, accuracy: 0.79,test_loss:4.43, test_acc: 0.64 \n",
      "Epoch 7 train_loss: 47.71, accuracy: 0.85,test_loss:4.83, test_acc: 0.64 \n",
      "Epoch 8 train_loss: 42.25, accuracy: 0.88,test_loss:5.04, test_acc: 0.61 \n",
      "Epoch 9 train_loss: 34.79, accuracy: 0.91,test_loss:5.2, test_acc: 0.65 \n",
      "Epoch 10 train_loss: 32.64, accuracy: 0.91,test_loss:6.39, test_acc: 0.64 \n",
      "Epoch 11 train_loss: 24.87, accuracy: 0.94,test_loss:6.77, test_acc: 0.58 \n",
      "Epoch 12 train_loss: 20.28, accuracy: 0.95,test_loss:5.75, test_acc: 0.68 \n",
      "Epoch 13 train_loss: 24.24, accuracy: 0.94,test_loss:6.49, test_acc: 0.64 \n",
      "Epoch 14 train_loss: 20.12, accuracy: 0.95,test_loss:7.13, test_acc: 0.68 \n",
      "Epoch 15 train_loss: 15.69, accuracy: 0.97,test_loss:6.75, test_acc: 0.67 \n",
      "Epoch 16 train_loss: 14.45, accuracy: 0.97,test_loss:7.83, test_acc: 0.65 \n",
      "Epoch 17 train_loss: 15.32, accuracy: 0.96,test_loss:8.35, test_acc: 0.66 \n",
      "Epoch 18 train_loss: 16.84, accuracy: 0.95,test_loss:8.04, test_acc: 0.64 \n",
      "Epoch 19 train_loss: 12.12, accuracy: 0.97,test_loss:8.39, test_acc: 0.62 \n",
      "Epoch 20 train_loss: 10.13, accuracy: 0.98,test_loss:8.86, test_acc: 0.68 \n",
      "Epoch 1 train_loss: 82.18, accuracy: 0.48,test_loss:5.01, test_acc: 0.45 \n",
      "Epoch 2 train_loss: 80.39, accuracy: 0.48,test_loss:4.9, test_acc: 0.47 \n",
      "Epoch 3 train_loss: 78.26, accuracy: 0.48,test_loss:4.8, test_acc: 0.47 \n",
      "Epoch 4 train_loss: 73.84, accuracy: 0.54,test_loss:4.78, test_acc: 0.57 \n",
      "Epoch 5 train_loss: 66.95, accuracy: 0.66,test_loss:4.5, test_acc: 0.61 \n",
      "Epoch 6 train_loss: 57.88, accuracy: 0.77,test_loss:4.53, test_acc: 0.66 \n",
      "Epoch 7 train_loss: 49.48, accuracy: 0.83,test_loss:5.2, test_acc: 0.65 \n",
      "Epoch 8 train_loss: 42.86, accuracy: 0.88,test_loss:5.95, test_acc: 0.64 \n",
      "Epoch 9 train_loss: 39.98, accuracy: 0.89,test_loss:6.26, test_acc: 0.59 \n",
      "Epoch 10 train_loss: 32.79, accuracy: 0.91,test_loss:6.25, test_acc: 0.62 \n",
      "Epoch 11 train_loss: 29.08, accuracy: 0.93,test_loss:6.38, test_acc: 0.6 \n",
      "Epoch 12 train_loss: 29.91, accuracy: 0.92,test_loss:6.49, test_acc: 0.64 \n",
      "Epoch 13 train_loss: 27.61, accuracy: 0.93,test_loss:6.15, test_acc: 0.65 \n",
      "Epoch 14 train_loss: 21.27, accuracy: 0.95,test_loss:7.73, test_acc: 0.62 \n",
      "Epoch 15 train_loss: 21.53, accuracy: 0.94,test_loss:6.89, test_acc: 0.62 \n",
      "Epoch 16 train_loss: 19.21, accuracy: 0.95,test_loss:6.81, test_acc: 0.65 \n",
      "Epoch 17 train_loss: 17.58, accuracy: 0.96,test_loss:7.89, test_acc: 0.64 \n",
      "Epoch 18 train_loss: 13.08, accuracy: 0.98,test_loss:7.7, test_acc: 0.65 \n",
      "Epoch 19 train_loss: 11.71, accuracy: 0.98,test_loss:8.03, test_acc: 0.65 \n",
      "Epoch 20 train_loss: 12.67, accuracy: 0.97,test_loss:9.44, test_acc: 0.64 \n",
      "Epoch 1 train_loss: 80.37, accuracy: 0.5,test_loss:4.85, test_acc: 0.47 \n",
      "Epoch 2 train_loss: 79.06, accuracy: 0.6,test_loss:4.78, test_acc: 0.59 \n",
      "Epoch 3 train_loss: 75.84, accuracy: 0.72,test_loss:4.74, test_acc: 0.54 \n",
      "Epoch 4 train_loss: 69.73, accuracy: 0.76,test_loss:4.8, test_acc: 0.56 \n",
      "Epoch 5 train_loss: 61.28, accuracy: 0.8,test_loss:5.08, test_acc: 0.54 \n",
      "Epoch 6 train_loss: 50.18, accuracy: 0.84,test_loss:5.46, test_acc: 0.58 \n",
      "Epoch 7 train_loss: 42.96, accuracy: 0.87,test_loss:6.1, test_acc: 0.54 \n",
      "Epoch 8 train_loss: 33.98, accuracy: 0.91,test_loss:6.6, test_acc: 0.56 \n",
      "Epoch 9 train_loss: 27.88, accuracy: 0.93,test_loss:7.52, test_acc: 0.55 \n",
      "Epoch 10 train_loss: 27.69, accuracy: 0.92,test_loss:8.29, test_acc: 0.57 \n",
      "Epoch 11 train_loss: 25.59, accuracy: 0.93,test_loss:9.08, test_acc: 0.52 \n",
      "Epoch 12 train_loss: 18.49, accuracy: 0.96,test_loss:10.16, test_acc: 0.55 \n",
      "Epoch 13 train_loss: 14.57, accuracy: 0.97,test_loss:10.22, test_acc: 0.57 \n",
      "Epoch 14 train_loss: 15.99, accuracy: 0.96,test_loss:11.59, test_acc: 0.52 \n",
      "Epoch 15 train_loss: 15.76, accuracy: 0.97,test_loss:11.31, test_acc: 0.53 \n",
      "Epoch 16 train_loss: 11.71, accuracy: 0.98,test_loss:12.9, test_acc: 0.51 \n",
      "Epoch 17 train_loss: 13.07, accuracy: 0.98,test_loss:12.49, test_acc: 0.55 \n",
      "Epoch 18 train_loss: 14.65, accuracy: 0.96,test_loss:12.34, test_acc: 0.55 \n",
      "Epoch 19 train_loss: 8.46, accuracy: 0.99,test_loss:13.56, test_acc: 0.5 \n",
      "Epoch 20 train_loss: 6.15, accuracy: 0.99,test_loss:13.08, test_acc: 0.57 \n",
      "Epoch 1 train_loss: 80.3, accuracy: 0.52,test_loss:4.84, test_acc: 0.53 \n",
      "Epoch 2 train_loss: 79.6, accuracy: 0.53,test_loss:4.76, test_acc: 0.55 \n",
      "Epoch 3 train_loss: 77.36, accuracy: 0.62,test_loss:4.67, test_acc: 0.65 \n",
      "Epoch 4 train_loss: 72.48, accuracy: 0.72,test_loss:4.5, test_acc: 0.66 \n",
      "Epoch 5 train_loss: 65.81, accuracy: 0.78,test_loss:4.49, test_acc: 0.63 \n",
      "Epoch 6 train_loss: 54.99, accuracy: 0.84,test_loss:4.57, test_acc: 0.66 \n",
      "Epoch 7 train_loss: 44.67, accuracy: 0.87,test_loss:5.25, test_acc: 0.57 \n",
      "Epoch 8 train_loss: 37.26, accuracy: 0.89,test_loss:6.0, test_acc: 0.59 \n",
      "Epoch 9 train_loss: 29.09, accuracy: 0.93,test_loss:6.63, test_acc: 0.6 \n",
      "Epoch 10 train_loss: 25.47, accuracy: 0.94,test_loss:7.18, test_acc: 0.6 \n",
      "Epoch 11 train_loss: 20.22, accuracy: 0.96,test_loss:7.31, test_acc: 0.62 \n",
      "Epoch 12 train_loss: 16.36, accuracy: 0.96,test_loss:8.96, test_acc: 0.6 \n",
      "Epoch 13 train_loss: 19.28, accuracy: 0.95,test_loss:8.36, test_acc: 0.59 \n",
      "Epoch 14 train_loss: 16.36, accuracy: 0.96,test_loss:8.12, test_acc: 0.62 \n",
      "Epoch 15 train_loss: 11.31, accuracy: 0.98,test_loss:8.95, test_acc: 0.62 \n",
      "Epoch 16 train_loss: 9.97, accuracy: 0.98,test_loss:9.83, test_acc: 0.6 \n",
      "Epoch 17 train_loss: 9.79, accuracy: 0.98,test_loss:10.5, test_acc: 0.58 \n",
      "Epoch 18 train_loss: 16.03, accuracy: 0.96,test_loss:9.58, test_acc: 0.61 \n",
      "Epoch 19 train_loss: 10.76, accuracy: 0.97,test_loss:10.23, test_acc: 0.61 \n",
      "Epoch 20 train_loss: 7.65, accuracy: 0.98,test_loss:9.75, test_acc: 0.63 \n",
      "Epoch 1 train_loss: 80.2, accuracy: 0.53,test_loss:4.85, test_acc: 0.51 \n",
      "Epoch 2 train_loss: 79.51, accuracy: 0.59,test_loss:4.79, test_acc: 0.61 \n",
      "Epoch 3 train_loss: 78.31, accuracy: 0.67,test_loss:4.75, test_acc: 0.64 \n",
      "Epoch 4 train_loss: 75.21, accuracy: 0.71,test_loss:4.61, test_acc: 0.62 \n",
      "Epoch 5 train_loss: 69.69, accuracy: 0.75,test_loss:4.56, test_acc: 0.66 \n",
      "Epoch 6 train_loss: 58.3, accuracy: 0.84,test_loss:4.99, test_acc: 0.59 \n",
      "Epoch 7 train_loss: 46.68, accuracy: 0.88,test_loss:5.17, test_acc: 0.58 \n",
      "Epoch 8 train_loss: 39.42, accuracy: 0.89,test_loss:5.41, test_acc: 0.58 \n",
      "Epoch 9 train_loss: 30.82, accuracy: 0.93,test_loss:5.98, test_acc: 0.61 \n",
      "Epoch 10 train_loss: 30.5, accuracy: 0.92,test_loss:6.58, test_acc: 0.61 \n",
      "Epoch 11 train_loss: 23.65, accuracy: 0.94,test_loss:6.87, test_acc: 0.61 \n",
      "Epoch 12 train_loss: 18.89, accuracy: 0.96,test_loss:7.9, test_acc: 0.58 \n",
      "Epoch 13 train_loss: 15.41, accuracy: 0.97,test_loss:8.02, test_acc: 0.61 \n",
      "Epoch 14 train_loss: 13.87, accuracy: 0.97,test_loss:8.49, test_acc: 0.6 \n",
      "Epoch 15 train_loss: 10.01, accuracy: 0.98,test_loss:9.79, test_acc: 0.6 \n",
      "Epoch 16 train_loss: 10.2, accuracy: 0.98,test_loss:10.14, test_acc: 0.58 \n",
      "Epoch 17 train_loss: 14.66, accuracy: 0.97,test_loss:10.39, test_acc: 0.59 \n",
      "Epoch 18 train_loss: 10.44, accuracy: 0.98,test_loss:10.91, test_acc: 0.55 \n",
      "Epoch 19 train_loss: 12.03, accuracy: 0.97,test_loss:11.84, test_acc: 0.57 \n",
      "Epoch 20 train_loss: 7.82, accuracy: 0.98,test_loss:12.22, test_acc: 0.53 \n",
      "Epoch 1 train_loss: 80.27, accuracy: 0.52,test_loss:4.85, test_acc: 0.51 \n",
      "Epoch 2 train_loss: 79.4, accuracy: 0.57,test_loss:4.81, test_acc: 0.6 \n",
      "Epoch 3 train_loss: 78.15, accuracy: 0.66,test_loss:4.74, test_acc: 0.66 \n",
      "Epoch 4 train_loss: 75.46, accuracy: 0.72,test_loss:4.67, test_acc: 0.62 \n",
      "Epoch 5 train_loss: 70.46, accuracy: 0.79,test_loss:4.59, test_acc: 0.68 \n",
      "Epoch 6 train_loss: 61.29, accuracy: 0.83,test_loss:4.54, test_acc: 0.68 \n",
      "Epoch 7 train_loss: 51.68, accuracy: 0.87,test_loss:4.76, test_acc: 0.69 \n",
      "Epoch 8 train_loss: 40.49, accuracy: 0.89,test_loss:5.03, test_acc: 0.62 \n",
      "Epoch 9 train_loss: 36.47, accuracy: 0.9,test_loss:5.57, test_acc: 0.62 \n",
      "Epoch 10 train_loss: 35.58, accuracy: 0.9,test_loss:7.23, test_acc: 0.5 \n",
      "Epoch 11 train_loss: 26.98, accuracy: 0.94,test_loss:6.36, test_acc: 0.66 \n",
      "Epoch 12 train_loss: 26.57, accuracy: 0.93,test_loss:7.15, test_acc: 0.58 \n",
      "Epoch 13 train_loss: 19.99, accuracy: 0.95,test_loss:7.21, test_acc: 0.63 \n",
      "Epoch 14 train_loss: 17.27, accuracy: 0.96,test_loss:7.65, test_acc: 0.63 \n",
      "Epoch 15 train_loss: 18.61, accuracy: 0.95,test_loss:8.84, test_acc: 0.58 \n",
      "Epoch 16 train_loss: 15.51, accuracy: 0.97,test_loss:9.05, test_acc: 0.57 \n",
      "Epoch 17 train_loss: 16.53, accuracy: 0.96,test_loss:8.37, test_acc: 0.63 \n",
      "Epoch 18 train_loss: 14.06, accuracy: 0.97,test_loss:8.79, test_acc: 0.6 \n",
      "Epoch 19 train_loss: 13.33, accuracy: 0.97,test_loss:8.47, test_acc: 0.63 \n",
      "Epoch 20 train_loss: 12.81, accuracy: 0.97,test_loss:8.58, test_acc: 0.64 \n",
      "Epoch 1 train_loss: 80.75, accuracy: 0.48,test_loss:4.88, test_acc: 0.47 \n",
      "Epoch 2 train_loss: 79.67, accuracy: 0.53,test_loss:4.83, test_acc: 0.55 \n",
      "Epoch 3 train_loss: 77.65, accuracy: 0.63,test_loss:4.8, test_acc: 0.6 \n",
      "Epoch 4 train_loss: 73.72, accuracy: 0.72,test_loss:4.75, test_acc: 0.59 \n",
      "Epoch 5 train_loss: 65.94, accuracy: 0.79,test_loss:4.85, test_acc: 0.58 \n",
      "Epoch 6 train_loss: 55.52, accuracy: 0.85,test_loss:5.58, test_acc: 0.48 \n",
      "Epoch 7 train_loss: 47.51, accuracy: 0.86,test_loss:5.69, test_acc: 0.58 \n",
      "Epoch 8 train_loss: 37.45, accuracy: 0.91,test_loss:6.04, test_acc: 0.58 \n",
      "Epoch 9 train_loss: 31.4, accuracy: 0.92,test_loss:7.34, test_acc: 0.53 \n",
      "Epoch 10 train_loss: 28.45, accuracy: 0.93,test_loss:7.4, test_acc: 0.55 \n",
      "Epoch 11 train_loss: 22.87, accuracy: 0.95,test_loss:8.77, test_acc: 0.53 \n",
      "Epoch 12 train_loss: 20.24, accuracy: 0.95,test_loss:8.77, test_acc: 0.57 \n",
      "Epoch 13 train_loss: 17.01, accuracy: 0.97,test_loss:10.11, test_acc: 0.54 \n",
      "Epoch 14 train_loss: 19.15, accuracy: 0.95,test_loss:10.53, test_acc: 0.53 \n",
      "Epoch 15 train_loss: 15.92, accuracy: 0.97,test_loss:9.13, test_acc: 0.62 \n",
      "Epoch 16 train_loss: 18.63, accuracy: 0.95,test_loss:10.28, test_acc: 0.57 \n",
      "Epoch 17 train_loss: 13.52, accuracy: 0.97,test_loss:9.46, test_acc: 0.58 \n",
      "Epoch 18 train_loss: 10.15, accuracy: 0.98,test_loss:9.95, test_acc: 0.58 \n",
      "Epoch 19 train_loss: 8.79, accuracy: 0.98,test_loss:12.18, test_acc: 0.53 \n",
      "Epoch 20 train_loss: 7.52, accuracy: 0.99,test_loss:12.08, test_acc: 0.59 \n",
      "Epoch 1 train_loss: 80.32, accuracy: 0.5,test_loss:4.86, test_acc: 0.46 \n",
      "Epoch 2 train_loss: 78.3, accuracy: 0.66,test_loss:4.76, test_acc: 0.57 \n",
      "Epoch 3 train_loss: 75.26, accuracy: 0.72,test_loss:4.62, test_acc: 0.62 \n",
      "Epoch 4 train_loss: 70.74, accuracy: 0.75,test_loss:4.61, test_acc: 0.62 \n",
      "Epoch 5 train_loss: 62.53, accuracy: 0.8,test_loss:4.65, test_acc: 0.62 \n",
      "Epoch 6 train_loss: 56.6, accuracy: 0.83,test_loss:4.5, test_acc: 0.65 \n",
      "Epoch 7 train_loss: 45.23, accuracy: 0.89,test_loss:4.74, test_acc: 0.63 \n",
      "Epoch 8 train_loss: 40.93, accuracy: 0.89,test_loss:5.34, test_acc: 0.6 \n",
      "Epoch 9 train_loss: 34.94, accuracy: 0.91,test_loss:6.73, test_acc: 0.53 \n",
      "Epoch 10 train_loss: 29.16, accuracy: 0.93,test_loss:6.48, test_acc: 0.59 \n",
      "Epoch 11 train_loss: 26.97, accuracy: 0.93,test_loss:7.25, test_acc: 0.57 \n",
      "Epoch 12 train_loss: 22.02, accuracy: 0.95,test_loss:8.6, test_acc: 0.51 \n",
      "Epoch 13 train_loss: 16.76, accuracy: 0.96,test_loss:8.85, test_acc: 0.52 \n",
      "Epoch 14 train_loss: 20.58, accuracy: 0.95,test_loss:8.81, test_acc: 0.55 \n",
      "Epoch 15 train_loss: 13.43, accuracy: 0.97,test_loss:10.02, test_acc: 0.56 \n",
      "Epoch 16 train_loss: 10.3, accuracy: 0.98,test_loss:11.29, test_acc: 0.56 \n",
      "Epoch 17 train_loss: 11.14, accuracy: 0.98,test_loss:10.91, test_acc: 0.58 \n",
      "Epoch 18 train_loss: 14.61, accuracy: 0.97,test_loss:13.15, test_acc: 0.48 \n",
      "Epoch 19 train_loss: 11.18, accuracy: 0.97,test_loss:12.53, test_acc: 0.51 \n",
      "Epoch 20 train_loss: 8.0, accuracy: 0.99,test_loss:12.23, test_acc: 0.58 \n",
      "Epoch 1 train_loss: 80.17, accuracy: 0.52,test_loss:4.84, test_acc: 0.53 \n",
      "Epoch 2 train_loss: 78.62, accuracy: 0.55,test_loss:4.81, test_acc: 0.56 \n",
      "Epoch 3 train_loss: 75.73, accuracy: 0.65,test_loss:4.62, test_acc: 0.61 \n",
      "Epoch 4 train_loss: 71.23, accuracy: 0.73,test_loss:4.57, test_acc: 0.64 \n",
      "Epoch 5 train_loss: 62.93, accuracy: 0.79,test_loss:4.63, test_acc: 0.59 \n",
      "Epoch 6 train_loss: 52.71, accuracy: 0.85,test_loss:4.38, test_acc: 0.63 \n",
      "Epoch 7 train_loss: 44.32, accuracy: 0.88,test_loss:5.31, test_acc: 0.58 \n",
      "Epoch 8 train_loss: 36.6, accuracy: 0.9,test_loss:5.45, test_acc: 0.6 \n",
      "Epoch 9 train_loss: 30.33, accuracy: 0.92,test_loss:6.16, test_acc: 0.58 \n",
      "Epoch 10 train_loss: 23.78, accuracy: 0.94,test_loss:6.96, test_acc: 0.61 \n",
      "Epoch 11 train_loss: 21.99, accuracy: 0.94,test_loss:7.1, test_acc: 0.63 \n",
      "Epoch 12 train_loss: 16.78, accuracy: 0.96,test_loss:8.43, test_acc: 0.58 \n",
      "Epoch 13 train_loss: 18.01, accuracy: 0.95,test_loss:8.33, test_acc: 0.61 \n",
      "Epoch 14 train_loss: 20.15, accuracy: 0.94,test_loss:7.69, test_acc: 0.66 \n",
      "Epoch 15 train_loss: 18.05, accuracy: 0.95,test_loss:8.18, test_acc: 0.59 \n",
      "Epoch 16 train_loss: 10.91, accuracy: 0.97,test_loss:8.63, test_acc: 0.61 \n",
      "Epoch 17 train_loss: 11.61, accuracy: 0.98,test_loss:8.16, test_acc: 0.66 \n",
      "Epoch 18 train_loss: 10.27, accuracy: 0.97,test_loss:9.05, test_acc: 0.65 \n",
      "Epoch 19 train_loss: 9.25, accuracy: 0.98,test_loss:9.05, test_acc: 0.66 \n",
      "Epoch 20 train_loss: 8.8, accuracy: 0.98,test_loss:9.36, test_acc: 0.62 \n",
      "Epoch 1 train_loss: 80.15, accuracy: 0.51,test_loss:4.81, test_acc: 0.68 \n",
      "Epoch 2 train_loss: 77.78, accuracy: 0.65,test_loss:4.58, test_acc: 0.67 \n",
      "Epoch 3 train_loss: 75.3, accuracy: 0.69,test_loss:4.46, test_acc: 0.68 \n",
      "Epoch 4 train_loss: 70.81, accuracy: 0.77,test_loss:4.31, test_acc: 0.72 \n",
      "Epoch 5 train_loss: 63.09, accuracy: 0.81,test_loss:4.03, test_acc: 0.78 \n",
      "Epoch 6 train_loss: 55.31, accuracy: 0.84,test_loss:4.08, test_acc: 0.73 \n",
      "Epoch 7 train_loss: 45.83, accuracy: 0.89,test_loss:4.63, test_acc: 0.74 \n",
      "Epoch 8 train_loss: 41.28, accuracy: 0.9,test_loss:4.86, test_acc: 0.71 \n",
      "Epoch 9 train_loss: 35.21, accuracy: 0.91,test_loss:5.26, test_acc: 0.7 \n",
      "Epoch 10 train_loss: 28.41, accuracy: 0.93,test_loss:5.24, test_acc: 0.72 \n",
      "Epoch 11 train_loss: 26.51, accuracy: 0.93,test_loss:6.02, test_acc: 0.71 \n",
      "Epoch 12 train_loss: 29.09, accuracy: 0.92,test_loss:6.66, test_acc: 0.64 \n",
      "Epoch 13 train_loss: 22.77, accuracy: 0.95,test_loss:6.72, test_acc: 0.68 \n",
      "Epoch 14 train_loss: 25.02, accuracy: 0.94,test_loss:6.06, test_acc: 0.73 \n",
      "Epoch 15 train_loss: 18.43, accuracy: 0.95,test_loss:6.89, test_acc: 0.67 \n",
      "Epoch 16 train_loss: 22.74, accuracy: 0.95,test_loss:7.25, test_acc: 0.68 \n",
      "Epoch 17 train_loss: 16.18, accuracy: 0.96,test_loss:8.82, test_acc: 0.64 \n",
      "Epoch 18 train_loss: 14.39, accuracy: 0.97,test_loss:8.2, test_acc: 0.66 \n",
      "Epoch 19 train_loss: 13.12, accuracy: 0.97,test_loss:8.79, test_acc: 0.66 \n",
      "Epoch 20 train_loss: 12.13, accuracy: 0.98,test_loss:9.02, test_acc: 0.65 \n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=10)\n",
    "scores = []\n",
    "cv_metrics = []\n",
    "for train, test in cv.split(df['FILE_ID'], df['TARGET']):\n",
    "    model = crnn()\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimiser =  optim.AdamW(model.parameters(), lr=0.0001, weight_decay = 1e-2)\n",
    "\n",
    "    train_df = df.iloc[train, :]\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    train_data = DfcDataset(train_df,data_dir)\n",
    "    train_dataloader = DataLoader(train_data, batch_size= 16,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=0)\n",
    "    test_df = df.iloc[test, :]\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    test_data = DfcDataset(test_df,data_dir)\n",
    "    test_dataloader = DataLoader(test_data, batch_size= 16,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=0)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    test_loss_history = []\n",
    "    test_acc_history = []\n",
    "    for i in range(20):\n",
    "\n",
    "      model.train()\n",
    "      train_loss, train_acc = train_one_epoch(model,loss_fn,optimiser,train_dataloader,device)\n",
    "\n",
    "\n",
    "      train_loss_history.append(train_loss)\n",
    "      train_acc_history.append(train_acc)\n",
    "\n",
    "      model.eval()\n",
    "      test_loss, test_acc = validate_one_epoch(model,loss_fn, test_dataloader,device)\n",
    "\n",
    "      test_loss_history.append(test_loss)\n",
    "      test_acc_history.append(test_acc)\n",
    "\n",
    "  \n",
    "\n",
    "      \n",
    "      print(f'Epoch {i + 1} train_loss: {round(train_loss, 2)}, accuracy: {round(train_acc, 2)},'\n",
    "              f'test_loss:{round(test_loss, 2)}, test_acc: {round(test_acc, 2)} ')\n",
    "\n",
    "\n",
    "\n",
    "    metrics = {'train_acc_history': train_acc_history, 'train_loss_history': train_loss_history,\n",
    "               'test_acc': test_acc_history, 'test_loss': test_loss_history}  # make dictionary of metrics\n",
    "    cv_metrics.append(metrics)\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wt6SzKdYsJue",
    "outputId": "10e9f517-7e91-4214-d853-f567bb647396"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "    os.mkdir('model_evaluation')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "mod_eval_p = 'model_evaluation'# path to subdirectory for model evaluation storage\n",
    "\n",
    "met_path = os.path.join(mod_eval_p, 'crnn5_cv_metrics.pickle') # path to pickle name for metric storage\n",
    "\n",
    "with open(met_path, 'wb') as handle:\n",
    "    pickle.dump(cv_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "id": "cnWcY_gVgYJV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "NNL-mIjNl0xO"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}