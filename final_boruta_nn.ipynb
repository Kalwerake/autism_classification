{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fully connected Neural Network and Ensemble model"
      ],
      "metadata": {
        "id": "sY_A6wC8w01A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "x7HZ8_U5gw8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d37d4d-9916-49c6-f0d6-1d3609ab1cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from scipy.stats import mode"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2jDCQniSRpVe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# upload cc400 filtered fc dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Project/vectorised/fc_cc400_filtered.csv')\n",
        "\n",
        "# if on local host\n",
        "# df = pd.read_csv('vectorised/fc_cc400_filtered.csv')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jT2kaalWRpVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "Klbzk3iQRe3C",
        "outputId": "e3687c1b-c455-4692-86af-d0ca12707f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      #5-#182   #5-#230   #5-#390   #8-#224    #9-#55   #10-#18  #10-#133  \\\n",
              "0   -0.465351 -0.038908 -0.303455  0.061997  0.285353 -0.302591 -0.575635   \n",
              "1   -0.009303  0.247179  0.019453 -0.089782  0.118145  0.045821 -0.036047   \n",
              "2   -0.131458  0.072728  0.090999  0.324135  0.235671 -0.226198 -0.300777   \n",
              "3    0.155183  0.077839  0.129694 -0.299517  0.191523 -0.196390 -0.279142   \n",
              "4   -0.005694 -0.116649  0.046553 -0.101360 -0.211751  0.016708 -0.093205   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "944  0.242785  0.333870  0.324636 -0.013359  0.227179  0.246499  0.280949   \n",
              "945 -0.190760 -0.086610 -0.045279 -0.212172  0.302947  0.140238  0.121516   \n",
              "946  0.138792  0.152113  0.253272 -0.215632  0.052178 -0.371396 -0.358475   \n",
              "947 -0.027725  0.081142  0.384957 -0.146337 -0.330887  0.068879  0.120493   \n",
              "948 -0.128754 -0.015408  0.037636 -0.180983  0.395113 -0.140900 -0.170114   \n",
              "\n",
              "     #10-#239  #10-#390   #11-#82  ...  #310-#390  #315-#346  #317-#347  \\\n",
              "0    0.093608 -0.311941  0.502320  ...   0.105564   0.281348  -0.078890   \n",
              "1    0.138405  0.046357  0.364785  ...   0.006089   0.052901  -0.005255   \n",
              "2    0.442815 -0.039074  0.477168  ...  -0.112499  -0.089670  -0.184399   \n",
              "3    0.075303  0.181871  0.709533  ...   0.117378  -0.332721  -0.203306   \n",
              "4    0.279462  0.240016  0.256403  ...   0.069215  -0.025669  -0.043941   \n",
              "..        ...       ...       ...  ...        ...        ...        ...   \n",
              "944 -0.473235  0.376639  0.405462  ...   0.177930  -0.399635  -0.147217   \n",
              "945 -0.039889  0.031693  0.288423  ...  -0.062911   0.255855   0.144863   \n",
              "946 -0.308918  0.345141  0.394936  ...  -0.033570  -0.459476   0.112224   \n",
              "947  0.010479  0.087033  0.419849  ...   0.002085   0.024210  -0.080221   \n",
              "948  0.087370  0.372089  0.728430  ...   0.048963   0.063733  -0.014204   \n",
              "\n",
              "     #318-#362  #323-#382  #323-#391  #335-#360  #343-#382  #356-#366  \\\n",
              "0     0.431270  -0.367768   0.088068   0.272958  -0.402212   0.349068   \n",
              "1     0.166180   0.029733  -0.006374   0.513472   0.115737   0.519810   \n",
              "2     0.130349   0.320956   0.134839   0.131533  -0.027364   0.234810   \n",
              "3     0.292701   0.187288  -0.461183   0.044323  -0.016915   0.198380   \n",
              "4     0.474094   0.048160  -0.178296   0.238861  -0.083691  -0.080434   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "944   0.157535  -0.168862   0.141573   0.085821   0.174607   0.022434   \n",
              "945   0.246999   0.206618  -0.105380  -0.088745   0.283497   0.294862   \n",
              "946   0.646445  -0.334266  -0.294695   0.314053   0.049902  -0.000490   \n",
              "947   0.254440  -0.138745   0.110950  -0.319803   0.143677  -0.130846   \n",
              "948   0.311591  -0.113454  -0.239123   0.374160   0.182757   0.272708   \n",
              "\n",
              "     DX_GROUP  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  \n",
              "..        ...  \n",
              "944         1  \n",
              "945         1  \n",
              "946         1  \n",
              "947         1  \n",
              "948         1  \n",
              "\n",
              "[949 rows x 261 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75f6cc1d-36a1-42ed-9300-b64c684696c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#5-#182</th>\n",
              "      <th>#5-#230</th>\n",
              "      <th>#5-#390</th>\n",
              "      <th>#8-#224</th>\n",
              "      <th>#9-#55</th>\n",
              "      <th>#10-#18</th>\n",
              "      <th>#10-#133</th>\n",
              "      <th>#10-#239</th>\n",
              "      <th>#10-#390</th>\n",
              "      <th>#11-#82</th>\n",
              "      <th>...</th>\n",
              "      <th>#310-#390</th>\n",
              "      <th>#315-#346</th>\n",
              "      <th>#317-#347</th>\n",
              "      <th>#318-#362</th>\n",
              "      <th>#323-#382</th>\n",
              "      <th>#323-#391</th>\n",
              "      <th>#335-#360</th>\n",
              "      <th>#343-#382</th>\n",
              "      <th>#356-#366</th>\n",
              "      <th>DX_GROUP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.465351</td>\n",
              "      <td>-0.038908</td>\n",
              "      <td>-0.303455</td>\n",
              "      <td>0.061997</td>\n",
              "      <td>0.285353</td>\n",
              "      <td>-0.302591</td>\n",
              "      <td>-0.575635</td>\n",
              "      <td>0.093608</td>\n",
              "      <td>-0.311941</td>\n",
              "      <td>0.502320</td>\n",
              "      <td>...</td>\n",
              "      <td>0.105564</td>\n",
              "      <td>0.281348</td>\n",
              "      <td>-0.078890</td>\n",
              "      <td>0.431270</td>\n",
              "      <td>-0.367768</td>\n",
              "      <td>0.088068</td>\n",
              "      <td>0.272958</td>\n",
              "      <td>-0.402212</td>\n",
              "      <td>0.349068</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.009303</td>\n",
              "      <td>0.247179</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>-0.089782</td>\n",
              "      <td>0.118145</td>\n",
              "      <td>0.045821</td>\n",
              "      <td>-0.036047</td>\n",
              "      <td>0.138405</td>\n",
              "      <td>0.046357</td>\n",
              "      <td>0.364785</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006089</td>\n",
              "      <td>0.052901</td>\n",
              "      <td>-0.005255</td>\n",
              "      <td>0.166180</td>\n",
              "      <td>0.029733</td>\n",
              "      <td>-0.006374</td>\n",
              "      <td>0.513472</td>\n",
              "      <td>0.115737</td>\n",
              "      <td>0.519810</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.131458</td>\n",
              "      <td>0.072728</td>\n",
              "      <td>0.090999</td>\n",
              "      <td>0.324135</td>\n",
              "      <td>0.235671</td>\n",
              "      <td>-0.226198</td>\n",
              "      <td>-0.300777</td>\n",
              "      <td>0.442815</td>\n",
              "      <td>-0.039074</td>\n",
              "      <td>0.477168</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.112499</td>\n",
              "      <td>-0.089670</td>\n",
              "      <td>-0.184399</td>\n",
              "      <td>0.130349</td>\n",
              "      <td>0.320956</td>\n",
              "      <td>0.134839</td>\n",
              "      <td>0.131533</td>\n",
              "      <td>-0.027364</td>\n",
              "      <td>0.234810</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.155183</td>\n",
              "      <td>0.077839</td>\n",
              "      <td>0.129694</td>\n",
              "      <td>-0.299517</td>\n",
              "      <td>0.191523</td>\n",
              "      <td>-0.196390</td>\n",
              "      <td>-0.279142</td>\n",
              "      <td>0.075303</td>\n",
              "      <td>0.181871</td>\n",
              "      <td>0.709533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.117378</td>\n",
              "      <td>-0.332721</td>\n",
              "      <td>-0.203306</td>\n",
              "      <td>0.292701</td>\n",
              "      <td>0.187288</td>\n",
              "      <td>-0.461183</td>\n",
              "      <td>0.044323</td>\n",
              "      <td>-0.016915</td>\n",
              "      <td>0.198380</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.005694</td>\n",
              "      <td>-0.116649</td>\n",
              "      <td>0.046553</td>\n",
              "      <td>-0.101360</td>\n",
              "      <td>-0.211751</td>\n",
              "      <td>0.016708</td>\n",
              "      <td>-0.093205</td>\n",
              "      <td>0.279462</td>\n",
              "      <td>0.240016</td>\n",
              "      <td>0.256403</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069215</td>\n",
              "      <td>-0.025669</td>\n",
              "      <td>-0.043941</td>\n",
              "      <td>0.474094</td>\n",
              "      <td>0.048160</td>\n",
              "      <td>-0.178296</td>\n",
              "      <td>0.238861</td>\n",
              "      <td>-0.083691</td>\n",
              "      <td>-0.080434</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944</th>\n",
              "      <td>0.242785</td>\n",
              "      <td>0.333870</td>\n",
              "      <td>0.324636</td>\n",
              "      <td>-0.013359</td>\n",
              "      <td>0.227179</td>\n",
              "      <td>0.246499</td>\n",
              "      <td>0.280949</td>\n",
              "      <td>-0.473235</td>\n",
              "      <td>0.376639</td>\n",
              "      <td>0.405462</td>\n",
              "      <td>...</td>\n",
              "      <td>0.177930</td>\n",
              "      <td>-0.399635</td>\n",
              "      <td>-0.147217</td>\n",
              "      <td>0.157535</td>\n",
              "      <td>-0.168862</td>\n",
              "      <td>0.141573</td>\n",
              "      <td>0.085821</td>\n",
              "      <td>0.174607</td>\n",
              "      <td>0.022434</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>945</th>\n",
              "      <td>-0.190760</td>\n",
              "      <td>-0.086610</td>\n",
              "      <td>-0.045279</td>\n",
              "      <td>-0.212172</td>\n",
              "      <td>0.302947</td>\n",
              "      <td>0.140238</td>\n",
              "      <td>0.121516</td>\n",
              "      <td>-0.039889</td>\n",
              "      <td>0.031693</td>\n",
              "      <td>0.288423</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.062911</td>\n",
              "      <td>0.255855</td>\n",
              "      <td>0.144863</td>\n",
              "      <td>0.246999</td>\n",
              "      <td>0.206618</td>\n",
              "      <td>-0.105380</td>\n",
              "      <td>-0.088745</td>\n",
              "      <td>0.283497</td>\n",
              "      <td>0.294862</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>946</th>\n",
              "      <td>0.138792</td>\n",
              "      <td>0.152113</td>\n",
              "      <td>0.253272</td>\n",
              "      <td>-0.215632</td>\n",
              "      <td>0.052178</td>\n",
              "      <td>-0.371396</td>\n",
              "      <td>-0.358475</td>\n",
              "      <td>-0.308918</td>\n",
              "      <td>0.345141</td>\n",
              "      <td>0.394936</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.033570</td>\n",
              "      <td>-0.459476</td>\n",
              "      <td>0.112224</td>\n",
              "      <td>0.646445</td>\n",
              "      <td>-0.334266</td>\n",
              "      <td>-0.294695</td>\n",
              "      <td>0.314053</td>\n",
              "      <td>0.049902</td>\n",
              "      <td>-0.000490</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>947</th>\n",
              "      <td>-0.027725</td>\n",
              "      <td>0.081142</td>\n",
              "      <td>0.384957</td>\n",
              "      <td>-0.146337</td>\n",
              "      <td>-0.330887</td>\n",
              "      <td>0.068879</td>\n",
              "      <td>0.120493</td>\n",
              "      <td>0.010479</td>\n",
              "      <td>0.087033</td>\n",
              "      <td>0.419849</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002085</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>-0.080221</td>\n",
              "      <td>0.254440</td>\n",
              "      <td>-0.138745</td>\n",
              "      <td>0.110950</td>\n",
              "      <td>-0.319803</td>\n",
              "      <td>0.143677</td>\n",
              "      <td>-0.130846</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>-0.128754</td>\n",
              "      <td>-0.015408</td>\n",
              "      <td>0.037636</td>\n",
              "      <td>-0.180983</td>\n",
              "      <td>0.395113</td>\n",
              "      <td>-0.140900</td>\n",
              "      <td>-0.170114</td>\n",
              "      <td>0.087370</td>\n",
              "      <td>0.372089</td>\n",
              "      <td>0.728430</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048963</td>\n",
              "      <td>0.063733</td>\n",
              "      <td>-0.014204</td>\n",
              "      <td>0.311591</td>\n",
              "      <td>-0.113454</td>\n",
              "      <td>-0.239123</td>\n",
              "      <td>0.374160</td>\n",
              "      <td>0.182757</td>\n",
              "      <td>0.272708</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>949 rows × 261 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75f6cc1d-36a1-42ed-9300-b64c684696c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75f6cc1d-36a1-42ed-9300-b64c684696c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75f6cc1d-36a1-42ed-9300-b64c684696c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Netork"
      ],
      "metadata": {
        "collapsed": false,
        "id": "g1aRFmUcRpVi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# isolate features\n",
        "features = df.iloc[:,:-1].columns.to_list()\n",
        "# targets\n",
        "target = \"DX_GROUP\""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "X_dkjMOERpVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "class VectorisedData(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset class for tabular data\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        \"\"\"\n",
        "        csv_file: tabular dataset\n",
        "        \"\"\"\n",
        "        self.df = csv_file\n",
        "\n",
        "        # Grouping variable names\n",
        "        self.features = self.df.iloc[:,:-1].columns.to_list()\n",
        "        self.target = \"DX_GROUP\"\n",
        "\n",
        "\n",
        "        # Save target and predictors\n",
        "        self.X = self.df.drop(self.target, axis=1)\n",
        "        self.y = self.df[self.target]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
        "        if isinstance(idx, torch.Tensor):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # return numpy array of dtype flt32 to be comabitlple with torch\n",
        "        return [self.X.iloc[idx].values.astype(np.float32), self.y[idx].astype(np.float32)]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "L6GRHMHfRpVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fully connected neural network for cc400 vectorised data\n",
        "class CC400_NN1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CC400_NN1, self).__init__()\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.seq_dense = nn.Sequential(\n",
        "            nn.Linear(260,130),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(130,60),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(60,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.seq_dense(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZvpxOsxU0TA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train_one_epoch_binary(model, loss_fn, optimiser, train_loader, device):\n",
        "   \"\"\"\n",
        "    Function for training one epoch\n",
        "    model: model class (pytorch module)\n",
        "    loss_fn: loss function, (pytorch module)\n",
        "    optimiser: optimser (pytorch module)\n",
        "    train_loader: train set dataloader (pytorch DataLoader class)\n",
        "    \"\"\"\n",
        "    running_loss = 0\n",
        "    epoch_accuracy = []\n",
        "    for j, (x_train, y) in enumerate(train_loader):\n",
        "        optimiser.zero_grad()  # zero the gradient at each epoch start\n",
        "        y = y.to(device)  # send y to cuda\n",
        "        y = y.unsqueeze(1)\n",
        "        x_train = x_train.to(device)\n",
        "        prediction = model.forward(x_train)\n",
        "        loss = loss_fn(prediction, y)  # loss\n",
        "        # calculate accuracy for each mini-batch  take prediction tensor, reshape to 1d detach from computational graph turn to numpy array, \n",
        "        #round and see if rounded number is equal to label, find mean of this boolean array, this is the accuracy\n",
        "        accuracy = (torch.round(\n",
        "            prediction) == y).float().mean()  \n",
        "\n",
        "        running_loss += loss.item()  # get epoch loss\n",
        "        epoch_accuracy.append(accuracy.item())\n",
        "\n",
        "        loss.backward()  # backward propagation\n",
        "        optimiser.step()\n",
        "\n",
        "        running_loss += loss.item()  # get epoch loss\n",
        "        epoch_accuracy.append(accuracy.item())\n",
        "\n",
        "    return running_loss, np.mean(epoch_accuracy)\n",
        "\n",
        "\n",
        "def validate_one_epoch_binary(model, loss_fn, test_loader, device):\n",
        "   \"\"\"\n",
        "       Function for validating one epoch\n",
        "       model: model class (pytorch module)\n",
        "       loss_fn: loss function, (pytorch module)\n",
        "       train_loader: test set dataloader (pytorch DataLoader class)\n",
        "       \"\"\"\n",
        "    test_loss_run = 0\n",
        "    test_acc_epoch = []\n",
        "    for j, (x_test, y_test) in enumerate(test_loader):\n",
        "        y_test = y_test.to(device)\n",
        "        y_test = y_test.unsqueeze(1)\n",
        "        x_test = x_test.to(device)\n",
        "        test_pred = model.forward(x_test)\n",
        "        test_loss = loss_fn(test_pred, y_test)  # loss\n",
        "\n",
        "        test_acc = (torch.round(\n",
        "            test_pred) == y_test).float().mean()  # calculate accuracy for each mini-batch  take prediction tensor, reshape to 1d detach from computational graph turn to numpy array, round and see if rounded number is equal to label, find mean of this boolean array, this is the accuracy\n",
        "\n",
        "        test_loss_run += test_loss.item()\n",
        "        test_acc_epoch.append(test_acc.item())\n",
        "\n",
        "    return test_loss_run, np.mean(test_acc_epoch)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7Kr68_dsRpVm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# set device to gpu if available ese cpu\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf6EoQ7oRpVm",
        "outputId": "d6f58e93-cdb8-49ea-b094-0cda0bdad303"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spec_sense(true_y, preds):\n",
        "    \"\"\"\n",
        "    Calculate specificity and sensitivity\n",
        "    true_y: True classes\n",
        "    preds: predicted classes\n",
        "    \"\"\"\n",
        "    # Use sklearn confusion matrixs to get true positive, etc\n",
        "    tn, fp, fn, tp = confusion_matrix(true_y, preds).ravel()\n",
        "    # calculate specificity and sensitivity\n",
        "    specificity = tn / (tn + fp)\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    # output specificity and sensitivity\n",
        "    return specificity, sensitivity\n"
      ],
      "metadata": {
        "id": "YF-hXYLOOrVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The FCN model is trained along with svm and lr models. All models are then combined together, and applied to the validation set to obtain prediction, this prediction is used to get validation accuracy, specificty etc"
      ],
      "metadata": {
        "id": "bHjmrRAl4jo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inialise shuffle split with 10 folds\n",
        "cv = StratifiedShuffleSplit(n_splits=10,random_state=0)\n",
        "cv_preds = []\n",
        "cv_true = []\n",
        "\n",
        "# metrics for neural network from all crossvalidation folds\n",
        "cv_accuracy_nn = []\n",
        "cv_sensitivity_nn = []\n",
        "cv_specificity_nn = []\n",
        "cv_f1_nn = []\n",
        "# metrics for logistic regression model\n",
        "cv_accuracy_lr = []\n",
        "cv_sensitivity_lr = []\n",
        "cv_specificity_lr = []\n",
        "cv_f1_lr = []\n",
        "# metrics for support vector machine\n",
        "cv_accuracy_svm = []\n",
        "cv_sensitivity_svm = []\n",
        "cv_specificity_svm = []\n",
        "cv_f1_svm = []\n",
        "# metrics for ensemble model\n",
        "cv_accuracy_ensemble = []\n",
        "cv_sensitivity_ensemble = []\n",
        "cv_specificity_ensemble = []\n",
        "cv_f1_ensemble = []\n",
        "# for each split in k-folds\n",
        "for train, test in cv.split(df[features], df[target]):\n",
        "    #initialise neural netowrk\n",
        "    model = CC400_NN1()\n",
        "    # initialise Binaru Cross entrophy loss function\n",
        "    loss_fn = nn.BCELoss()\n",
        "    # initialise Adam optimiser with learning rate of 0.0001 and weight decay 1e-1\n",
        "    optimiser = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-1)\n",
        "    # get train set\n",
        "    train_df = df.iloc[train, :]\n",
        "    # reset index so VectorisedData() does not throw out error\n",
        "    train_df.reset_index(drop=True, inplace=True)\n",
        "    train_data = VectorisedData(train_df)\n",
        "    # dataloader class with mini batch size of 3 \n",
        "    train_dataloader = DataLoader(train_data, batch_size= 3,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers=0)\n",
        "    \n",
        "    \n",
        "    # train network on gpu\n",
        "    model.to(device)\n",
        "    \n",
        "    train_loss_history = []\n",
        "    train_acc_history = []\n",
        "    test_loss_history = []\n",
        "    test_acc_history = []\n",
        "    # only train fcn for 10 epochs to prevent overfitting\n",
        "    for i in range(10):\n",
        "        # set fcn to training mode\n",
        "        model.train()\n",
        "        #  train one epoch get train loss and train_acc\n",
        "        train_loss, train_acc = train_one_epoch_binary(model, loss_fn, optimiser, train_dataloader, device)\n",
        "        # append to history lost\n",
        "        train_loss_history.append(train_loss)\n",
        "        train_acc_history.append(train_acc)\n",
        "    # isolat validation X and y for svm and lr training\n",
        "    X_train = df.iloc[train,:-1]\n",
        "    y_train = df.iloc[train,-1]\n",
        "    X_val = df.iloc[test,:-1]\n",
        "    y_val = df.iloc[test,-1]\n",
        "    # initialise svm and lr classes\n",
        "    svm = SVC(kernel='rbf')\n",
        "    lr = LogisticRegression()\n",
        "    # fit models\n",
        "    svm.fit(X_train, y_train)\n",
        "    lr.fit(X_train, y_train)\n",
        "    \n",
        "    # set network to evaluation mode for getting predictions on the validation set\n",
        "    model.eval()\n",
        "    # turn the validation X to numpy array and then to torch.Tensor\n",
        "    nn_input = torch.Tensor(X_val.to_numpy())\n",
        "    # send the input tensor to the gpu so it can be run given to the fcn\n",
        "    nn_input.to(device)\n",
        "    # get network predictions\n",
        "    nn_out = model.forward(nn_input.to(device))\n",
        "    # send fcn prediction back to cpu, detach so tensor does not require gradient\n",
        "    # turn detached tensor to numpy array, round flatten and set to integar\n",
        "    nn_predictions = np.round(nn_out.cpu().detach().numpy()).flatten().astype(dtype=int)\n",
        "    # get predicitons from svm and lr from validation X\n",
        "    svm_predictions = svm.predict(X_val)\n",
        "    lr_predictions = lr.predict(X_val)\n",
        "    \n",
        "    # get accuracy for all models\n",
        "    nn_accuracy = (nn_predictions == y_val).round().mean()\n",
        "    svm_accuracy = (svm_predictions == y_val).round().mean()\n",
        "    lr_accuracy = (lr_predictions == y_val).round().mean()\n",
        "    \n",
        "    # use get_spec_sense() to get specificity and sensitivity for all models\n",
        "    nn_specificity, nn_sensitivity = get_spec_sense(y_val , nn_predictions)\n",
        "    svm_specificity, svm_sensitivity = get_spec_sense(y_val , svm_predictions)\n",
        "    lr_specificity, lr_sensitivity = get_spec_sense(y_val , lr_predictions)\n",
        "    # get f1 scores\n",
        "    nn_f1 = f1_score(y_val , nn_predictions)\n",
        "    svm_f1 = f1_score(y_val , svm_predictions)\n",
        "    lr_f1 = f1_score(y_val , lr_predictions)\n",
        "    #  column wise concatanate all model predictions\n",
        "    # this makes a array of shape (sample size, 3), each row shows predicitons from all models\n",
        "    all_pred = np.c_[nn_predictions,lr_predictions,svm_predictions]\n",
        "    # initialise list for storing final prediction\n",
        "    final_preds = []\n",
        "    # iterate over row number\n",
        "    for i in range(len(all_pred)):\n",
        "      # get counts for each value in a row\n",
        "      values, counts = np.unique(all_pred[i,:], return_counts = True)\n",
        "      # get value with highest count and append to final_preds\n",
        "      # this is the ensemble model's prediction\n",
        "      final_preds.append(values[np.argmax(counts)])\n",
        "    # append the ensemble model's prediction to cv_preds\n",
        "    cv_preds.append(final_preds)\n",
        "    cv_true.append(y_val)\n",
        "    # get accuracy etc of the ensemble model\n",
        "    final_accuracy = (final_preds == y_val).round().mean()\n",
        "    final_specificity, final_sensitivity = get_spec_sense(y_val , final_preds)\n",
        "    final_f1 = f1_score(y_val , final_preds)\n",
        "\n",
        "    # append calculated metrics for from all models to associated list\n",
        "    cv_accuracy_nn.append(nn_accuracy)\n",
        "    cv_sensitivity_nn.append(nn_sensitivity)\n",
        "    cv_specificity_nn.append(nn_specificity)\n",
        "    cv_f1_nn.append(nn_f1)\n",
        "\n",
        "    cv_accuracy_svm.append(svm_accuracy)\n",
        "    cv_sensitivity_svm.append(svm_sensitivity)\n",
        "    cv_specificity_svm.append(svm_specificity)\n",
        "    cv_f1_svm.append(svm_f1)\n",
        "\n",
        "    cv_accuracy_lr.append(lr_accuracy)\n",
        "    cv_sensitivity_lr.append(lr_sensitivity)\n",
        "    cv_specificity_lr.append(lr_specificity)\n",
        "    cv_f1_lr.append(nn_f1)\n",
        "\n",
        "    cv_accuracy_ensemble.append(final_accuracy)\n",
        "    cv_sensitivity_ensemble.append(final_sensitivity)\n",
        "    cv_specificity_ensemble.append(final_specificity)\n",
        "    cv_f1_ensemble.append(final_f1)"
      ],
      "metadata": {
        "id": "xmXwxnGvSs83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make dictionary from all metric lists \n",
        "cv_metrics = {\"fcn_accuracy\" : cv_accuracy_nn, \"fcn_sensitivity\": cv_sensitivity_nn, \"fcn_specificity\": cv_specificity_nn, \"fcn_f1\" :cv_f1_nn,\n",
        "              \"lr_accuracy\": cv_accuracy_lr,\"lr_sensitivity\": cv_sensitivity_lr, \"lr_specificity\": cv_specificity_lr,\"lr_f1\": cv_f1_lr,\n",
        "              \"svm_accuracy\": cv_accuracy_svm, \"svm_sensitivity\": cv_sensitivity_svm,\"svm_specificity\":cv_specificity_svm, \"svm_f1\": cv_f1_svm,\n",
        "              \"ensemble_accuracy\" :cv_accuracy_ensemble, \"ensemble_sensitivity\": cv_sensitivity_ensemble, \n",
        "              \"ensemble_specificity\": cv_specificity_ensemble, \"ensemble_f1\": cv_f1_ensemble }"
      ],
      "metadata": {
        "id": "HCjEVSUFS0Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn metric dictionary to dataframe\n",
        "cv_metrics = pd.DataFrame(cv_metrics)"
      ],
      "metadata": {
        "id": "d6I9B3rFUkLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find means for each model\n",
        "cv_metrics.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLFqw9xXUxCF",
        "outputId": "d21f5699-9207-4428-d48a-68e00cc2cefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fcn_accuracy            0.797852\n",
              "fcn_sensitivity         0.757778\n",
              "fcn_specificity         0.834000\n",
              "fcn_f1                  0.780173\n",
              "lr_accuracy             0.780273\n",
              "lr_sensitivity          0.744444\n",
              "lr_specificity          0.812000\n",
              "lr_f1                   0.780173\n",
              "svm_accuracy            0.809570\n",
              "svm_sensitivity         0.760000\n",
              "svm_specificity         0.854000\n",
              "svm_f1                  0.790150\n",
              "ensemble_accuracy       0.811523\n",
              "ensemble_sensitivity    0.764444\n",
              "ensemble_specificity    0.854000\n",
              "ensemble_f1             0.793252\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save metrics as a csv file to model_evaluation/\n",
        "cv_metrics.to_csv('/content/drive/MyDrive/Project/model_evaluation/ensemble_metrics.csv', index = False)"
      ],
      "metadata": {
        "id": "OBEv2LfkVCpr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}